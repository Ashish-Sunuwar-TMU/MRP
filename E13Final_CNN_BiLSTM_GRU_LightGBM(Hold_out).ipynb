{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6VlAaGiHZvK",
        "outputId": "2204b7d3-e4b9-4539-e4bc-92d5e676e247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, GRU, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, brier_score_loss\n",
        ")\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Reproducibility & Load Data\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "file_path = '/content/drive/MyDrive/MRP/final_dataset.csv'\n",
        "df = pd.read_csv(file_path, parse_dates=['date'])\n",
        "df = df.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
        "\n",
        "# Feature Engineering\n",
        "# Multi-lag returns\n",
        "for lag in (1, 3, 5):\n",
        "    df[f'return_1d_lag{lag}'] = df.groupby('symbol')['return_1d'].shift(lag)\n",
        "\n",
        "# Rolling-window return stats\n",
        "df['return_7d_mean'] = df.groupby('symbol')['return_1d'].transform(lambda x: x.rolling(7).mean())\n",
        "df['return_7d_std']  = df.groupby('symbol')['return_1d'].transform(lambda x: x.rolling(7).std())\n",
        "\n",
        "# Rolling-window sentiment stats\n",
        "df['sentiment_7d_mean'] = df.groupby('symbol')['avg_sentiment'].transform(lambda x: x.rolling(7).mean())\n",
        "df['pos_sent_count_7d'] = df.groupby('symbol')['avg_sentiment']\\\n",
        "    .transform(lambda x: x.rolling(7).apply(lambda arr: (arr > 0).sum(), raw=True))\n",
        "df['neg_sent_count_7d'] = df.groupby('symbol')['avg_sentiment']\\\n",
        "    .transform(lambda x: x.rolling(7).apply(lambda arr: (arr < 0).sum(), raw=True))\n",
        "\n",
        "# One-hot encode day_of_week\n",
        "dow_ohe = pd.get_dummies(df['day_of_week'], prefix='dow', drop_first=True)\n",
        "df = pd.concat([df, dow_ohe], axis=1)\n",
        "\n",
        "# Drop any NA from shifts/rolling windows\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Build Sequence & Static Arrays\n",
        "price_feats = ['adj close','log_volume','ma_10','vol_30','rsi_14','return_1d_lag1']\n",
        "news_feats  = ['avg_sentiment','avg_sentiment_confidence','sentiment_std_7']\n",
        "eng_feats   = [\n",
        "    'return_1d_lag3','return_1d_lag5',\n",
        "    'return_7d_mean','return_7d_std',\n",
        "    'sentiment_7d_mean','pos_sent_count_7d','neg_sent_count_7d'\n",
        "]\n",
        "dow_feats   = [c for c in df.columns if c.startswith('dow_')]\n",
        "static_feats = price_feats + news_feats + eng_feats + dow_feats\n",
        "TARGET     = 'target'\n",
        "SEQ_LEN    = 30\n",
        "\n",
        "Xs, stat_X, ys, dates = [], [], [], []\n",
        "for sym, grp in df.groupby('symbol'):\n",
        "    grp = grp.sort_values('date').reset_index(drop=True)\n",
        "    seq_vals  = grp[price_feats].values\n",
        "    stat_vals = grp[static_feats].values\n",
        "    lbls      = grp[TARGET].values\n",
        "    dts       = grp['date'].values\n",
        "    for i in range(SEQ_LEN, len(grp)):\n",
        "        Xs.append(seq_vals[i-SEQ_LEN:i])\n",
        "        stat_X.append(stat_vals[i])\n",
        "        ys.append(lbls[i])\n",
        "        dates.append(dts[i])\n",
        "\n",
        "X        = np.stack(Xs).astype('float32')       # shape (N, SEQ_LEN, len(price_feats))\n",
        "static_X = np.stack(stat_X).astype('float32')   # shape (N, len(static_feats))\n",
        "y        = np.array(ys, dtype='float32')\n",
        "dates    = np.array(dates)\n",
        "\n",
        "# plit into Train+Val (≤2022-12-31) vs Test (2023)\n",
        "train_mask = dates <= np.datetime64('2022-12-31')\n",
        "test_mask  = dates >  np.datetime64('2022-12-31')\n",
        "\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "s_train, s_test = static_X[train_mask], static_X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "\n",
        "print(f\"Train samples: {len(y_train)}, Test samples: {len(y_test)}\")\n",
        "\n",
        "# Train CNN–BiLSTM–GRU Embedding Model on Full Training Set\n",
        "inp = Input(shape=(SEQ_LEN, X_train.shape[2]))\n",
        "x   = Conv1D(32, 3, padding='same', activation='relu')(inp)\n",
        "x   = Conv1D(32, 3, padding='same', activation='relu')(x)\n",
        "x   = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x   = GRU(32)(x)\n",
        "embed = Dropout(0.2)(x)\n",
        "out   = Dense(1, activation='sigmoid')(embed)\n",
        "seq_model = Model(inputs=inp, outputs=out)\n",
        "seq_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "seq_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=1024,\n",
        "    callbacks=[EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Extract Embeddings\n",
        "embed_model = Model(inputs=inp, outputs=embed)\n",
        "emb_train   = embed_model.predict(X_train, batch_size=1024)\n",
        "emb_test    = embed_model.predict(X_test,  batch_size=1024)\n",
        "\n",
        "# Train LightGBM on Hybrid Features\n",
        "train_feat = np.hstack([emb_train, s_train])\n",
        "test_feat  = np.hstack([emb_test,  s_test])\n",
        "\n",
        "clf = lgb.LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    num_leaves=127,\n",
        "    min_data_in_leaf=20,\n",
        "    learning_rate=0.01,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    verbosity=-1\n",
        ")\n",
        "clf.fit(train_feat, y_train)\n",
        "\n",
        "# Evaluate on 2023 Hold-out with τ=0.35\n",
        "y_prob = clf.predict_proba(test_feat)[:, 1]\n",
        "y_pred = (y_prob >= 0.35).astype(int)\n",
        "\n",
        "print(\"\\nFinal Hold-out (2023) Performance:\")\n",
        "print(f\"  Accuracy    : {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  Precision   : {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  Recall      : {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  F1 Score    : {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  ROC AUC     : {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "print(f\"  Brier Score : {brier_score_loss(y_test, y_prob):.4f}\")\n",
        "print(\"  Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_DweyoCHaUU",
        "outputId": "716de405-5444-42c0-fa30-c945a1c2b9ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4093085, Test samples: 571382\n",
            "Epoch 1/20\n",
            "3998/3998 - 82s - 21ms/step - accuracy: 0.5093 - loss: 0.6931\n",
            "Epoch 2/20\n",
            "3998/3998 - 78s - 19ms/step - accuracy: 0.5141 - loss: 0.6925\n",
            "Epoch 3/20\n",
            "3998/3998 - 78s - 20ms/step - accuracy: 0.5180 - loss: 0.6917\n",
            "Epoch 4/20\n",
            "3998/3998 - 78s - 20ms/step - accuracy: 0.5226 - loss: 0.6895\n",
            "Epoch 5/20\n",
            "3998/3998 - 78s - 19ms/step - accuracy: 0.5258 - loss: 0.6880\n",
            "Epoch 6/20\n",
            "3998/3998 - 78s - 19ms/step - accuracy: 0.5280 - loss: 0.6869\n",
            "Epoch 7/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5299 - loss: 0.6857\n",
            "Epoch 8/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5315 - loss: 0.6847\n",
            "Epoch 9/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5328 - loss: 0.6838\n",
            "Epoch 10/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5340 - loss: 0.6830\n",
            "Epoch 11/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5352 - loss: 0.6823\n",
            "Epoch 12/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5365 - loss: 0.6817\n",
            "Epoch 13/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5369 - loss: 0.6812\n",
            "Epoch 14/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5377 - loss: 0.6806\n",
            "Epoch 15/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5384 - loss: 0.6803\n",
            "Epoch 16/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5391 - loss: 0.6798\n",
            "Epoch 17/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5396 - loss: 0.6794\n",
            "Epoch 18/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5400 - loss: 0.6791\n",
            "Epoch 19/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5405 - loss: 0.6789\n",
            "Epoch 20/20\n",
            "3998/3998 - 77s - 19ms/step - accuracy: 0.5407 - loss: 0.6786\n",
            "\u001b[1m3998/3998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\n",
            "Final Hold-out (2023) Performance:\n",
            "  Accuracy    : 0.6825\n",
            "  Precision   : 0.6283\n",
            "  Recall      : 0.9061\n",
            "  F1 Score    : 0.7421\n",
            "  ROC AUC     : 0.8026\n",
            "  Brier Score : 0.1866\n",
            "  Confusion Matrix:\n",
            "[[128938 154397]\n",
            " [ 27045 261002]]\n"
          ]
        }
      ]
    }
  ]
}