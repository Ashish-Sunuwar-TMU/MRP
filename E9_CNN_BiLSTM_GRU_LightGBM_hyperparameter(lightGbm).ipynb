{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA2jLLCVM4mG",
        "outputId": "224d2fdb-5c9b-4d4f-9f5d-eff2e83ad977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, Bidirectional, LSTM, GRU, Dropout, Dense\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load & Prepare Data\n",
        "file_path = '/content/drive/MyDrive/MRP/final_dataset.csv'\n",
        "df = pd.read_csv(file_path, parse_dates=['date'])\n",
        "df = df.sort_values(['symbol','date']).reset_index(drop=True)\n",
        "\n",
        "# Compute 1-day lagged return and drop NaNs\n",
        "df['return_1d_lag1'] = df.groupby('symbol')['return_1d'].shift(1)\n",
        "df = df.dropna(subset=['return_1d_lag1']).reset_index(drop=True)\n",
        "\n",
        "# Define Features & Parameters\n",
        "price_feats  = ['adj close', 'log_volume', 'ma_10', 'vol_30', 'rsi_14', 'return_1d_lag1']\n",
        "news_feats   = ['avg_sentiment', 'avg_sentiment_confidence', 'sentiment_std_7']\n",
        "static_feats = price_feats + news_feats + ['day_of_week']\n",
        "TARGET       = 'target'\n",
        "SEQ_LEN      = 30\n",
        "\n",
        "# Generate Sequences & Static Vectors\n",
        "Xs, static_X, ys, dates = [], [], [], []\n",
        "for sym, grp in df.groupby('symbol'):\n",
        "    grp = grp.sort_values('date').reset_index(drop=True)\n",
        "    arr    = grp[price_feats].values\n",
        "    stat   = grp[static_feats].values\n",
        "    labels = grp[TARGET].values\n",
        "    dts    = grp['date'].values\n",
        "    for i in range(SEQ_LEN, len(grp)):\n",
        "        Xs.append(arr[i-SEQ_LEN:i])\n",
        "        static_X.append(stat[i])\n",
        "        ys.append(labels[i])\n",
        "        dates.append(dts[i])\n",
        "\n",
        "X         = np.stack(Xs).astype('float32')       # (N, SEQ_LEN, len(price_feats))\n",
        "static_X  = np.stack(static_X).astype('float32') # (N, len(static_feats))\n",
        "y         = np.array(ys, dtype='float32')\n",
        "dates     = np.array(dates)\n",
        "\n",
        "# Chronological Split\n",
        "train_mask = dates <= np.datetime64('2021-12-31')\n",
        "val_mask   = (dates > np.datetime64('2021-12-31')) & (dates <= np.datetime64('2022-12-31'))\n",
        "test_mask  = dates > np.datetime64('2022-12-31')\n",
        "\n",
        "X_train, X_val, X_test         = X[train_mask], X[val_mask], X[test_mask]\n",
        "static_train, static_val, static_test = static_X[train_mask], static_X[val_mask], static_X[test_mask]\n",
        "y_train, y_val, y_test         = y[train_mask], y[val_mask], y[test_mask]\n",
        "\n",
        "print(f\"Samples: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
        "\n",
        "# Build CNN–BiLSTM–GRU Embedding Model\n",
        "n_feats = X_train.shape[2]\n",
        "inputs = Input(shape=(SEQ_LEN, n_feats))\n",
        "x = Conv1D(32, 3, padding='same', activation='relu')(inputs)\n",
        "x = Conv1D(32, 3, padding='same', activation='relu')(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = GRU(32)(x)\n",
        "embed_output = Dropout(0.2)(x)  # embedding vector\n",
        "outputs = Dense(1, activation='sigmoid')(embed_output)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=1024,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Extract Embeddings\n",
        "embed_model = Model(inputs, embed_output)\n",
        "emb_train = embed_model.predict(X_train, batch_size=1024)\n",
        "emb_val   = embed_model.predict(X_val,   batch_size=1024)\n",
        "emb_test  = embed_model.predict(X_test,  batch_size=1024)\n",
        "\n",
        "# Combine with Static Features\n",
        "train_feat = np.hstack([emb_train, static_train])\n",
        "val_feat   = np.hstack([emb_val,   static_val])\n",
        "test_feat  = np.hstack([emb_test,  static_test])\n",
        "\n",
        "# grid‐search over key LightGBM hyperparameters on your validation split\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Define the grid of hyperparameters to try\n",
        "param_grid = {\n",
        "    'num_leaves':       [31, 63, 127],\n",
        "    'max_depth':        [-1, 10, 20],\n",
        "    'min_data_in_leaf': [20, 50, 100],\n",
        "    'learning_rate':    [0.01, 0.05, 0.1],\n",
        "}\n",
        "fixed_params = {\n",
        "    'n_estimators': 200,\n",
        "    'random_state': 42,\n",
        "    'n_jobs':      -1,\n",
        "    'verbosity':   -1,\n",
        "}\n",
        "\n",
        "best_f1 = -np.inf\n",
        "best_params = None\n",
        "\n",
        "# Loop over all combinations\n",
        "for num_leaves, max_depth, min_data in itertools.product(\n",
        "    param_grid['num_leaves'],\n",
        "    param_grid['max_depth'],\n",
        "    param_grid['min_data_in_leaf']\n",
        "):\n",
        "    for lr in param_grid['learning_rate']:\n",
        "        params = {\n",
        "            **fixed_params,\n",
        "            'num_leaves':       num_leaves,\n",
        "            'max_depth':        max_depth,\n",
        "            'min_data_in_leaf': min_data,\n",
        "            'learning_rate':    lr,\n",
        "        }\n",
        "        # Train on train_feat, early‐stop on val_feat\n",
        "        clf_cv = lgb.LGBMClassifier(**params)\n",
        "        clf_cv.fit(\n",
        "            train_feat, y_train,\n",
        "            eval_set=[(val_feat, y_val)],\n",
        "            eval_metric='binary_logloss',\n",
        "            callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        "        )\n",
        "\n",
        "        # Evaluate F1 on validation (threshold=0.5)\n",
        "        val_preds = (clf_cv.predict_proba(val_feat)[:,1] >= 0.5).astype(int)\n",
        "        f1 = f1_score(y_val, val_preds)\n",
        "        print(f\"leaves={num_leaves}, depth={max_depth}, min_leaf={min_data}, lr={lr} → F1={f1:.4f}\")\n",
        "\n",
        "        # Track best\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_params = params\n",
        "\n",
        "# Report the winner\n",
        "print(\"\\nBest hyperparameters on validation:\")\n",
        "print(best_params)\n",
        "print(f\"Best F1 on validation: {best_f1:.4f}\")\n",
        "\n",
        "\n",
        "# Train LightGBM on Hybrid Features\n",
        "clf = lgb.LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "clf.fit(\n",
        "    train_feat, y_train,\n",
        "    eval_set=[(val_feat, y_val)],\n",
        "    eval_metric='binary_logloss',\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=10),\n",
        "        lgb.log_evaluation(period=20)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate on Test Set\n",
        "y_pred = clf.predict(test_feat)\n",
        "y_prob = clf.predict_proba(test_feat)[:, 1]\n",
        "\n",
        "print(\"\\nHybrid CNN–BiLSTM–GRU → LightGBM Performance:\")\n",
        "print(f\"  Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  F1 Score : {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"  ROC AUC  : {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M_VPoW1jM6ri",
        "outputId": "3122c578-9d3c-4d50-9d7e-b271bb8970b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: Train=3477497, Val=642247, Test=571443\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m6\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m608\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m49,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m15,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,961\u001b[0m (269.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,961</span> (269.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,961\u001b[0m (269.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,961</span> (269.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3396/3396 - 76s - 22ms/step - accuracy: 0.5122 - loss: 0.6929 - val_accuracy: 0.5062 - val_loss: 0.6930\n",
            "Epoch 2/20\n",
            "3396/3396 - 70s - 20ms/step - accuracy: 0.5163 - loss: 0.6923 - val_accuracy: 0.5036 - val_loss: 0.6939\n",
            "Epoch 3/20\n",
            "3396/3396 - 70s - 20ms/step - accuracy: 0.5191 - loss: 0.6919 - val_accuracy: 0.5087 - val_loss: 0.6938\n",
            "Epoch 4/20\n",
            "3396/3396 - 69s - 20ms/step - accuracy: 0.5235 - loss: 0.6899 - val_accuracy: 0.5048 - val_loss: 0.6951\n",
            "\u001b[1m3396/3396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=-1, min_leaf=20, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=-1, min_leaf=20, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=-1, min_leaf=20, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=-1, min_leaf=50, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=-1, min_leaf=50, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=-1, min_leaf=50, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=-1, min_leaf=100, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=-1, min_leaf=100, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=-1, min_leaf=100, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=10, min_leaf=20, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=10, min_leaf=20, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=10, min_leaf=20, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=10, min_leaf=50, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=10, min_leaf=50, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=10, min_leaf=50, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=10, min_leaf=100, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=10, min_leaf=100, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=10, min_leaf=100, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=20, min_leaf=20, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=20, min_leaf=20, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=20, min_leaf=20, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=20, min_leaf=50, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=20, min_leaf=50, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=20, min_leaf=50, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=31, depth=20, min_leaf=100, lr=0.01 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "leaves=31, depth=20, min_leaf=100, lr=0.05 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694221\n",
            "leaves=31, depth=20, min_leaf=100, lr=0.1 → F1=0.6236\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=-1, min_leaf=20, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=-1, min_leaf=20, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=-1, min_leaf=20, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=-1, min_leaf=50, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=-1, min_leaf=50, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=-1, min_leaf=50, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=-1, min_leaf=100, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=-1, min_leaf=100, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=-1, min_leaf=100, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[38]\tvalid_0's binary_logloss: 0.69421\n",
            "leaves=63, depth=10, min_leaf=20, lr=0.01 → F1=0.6241\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.69422\n",
            "leaves=63, depth=10, min_leaf=20, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=10, min_leaf=20, lr=0.1 → F1=0.6194\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[38]\tvalid_0's binary_logloss: 0.69421\n",
            "leaves=63, depth=10, min_leaf=50, lr=0.01 → F1=0.6241\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.69422\n",
            "leaves=63, depth=10, min_leaf=50, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=10, min_leaf=50, lr=0.1 → F1=0.6194\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[38]\tvalid_0's binary_logloss: 0.69421\n",
            "leaves=63, depth=10, min_leaf=100, lr=0.01 → F1=0.6241\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.69422\n",
            "leaves=63, depth=10, min_leaf=100, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=10, min_leaf=100, lr=0.1 → F1=0.6194\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=20, min_leaf=20, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=20, min_leaf=20, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=20, min_leaf=20, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=20, min_leaf=50, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=20, min_leaf=50, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=20, min_leaf=50, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=63, depth=20, min_leaf=100, lr=0.01 → F1=0.6238\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694222\n",
            "leaves=63, depth=20, min_leaf=100, lr=0.05 → F1=0.6228\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694219\n",
            "leaves=63, depth=20, min_leaf=100, lr=0.1 → F1=0.6195\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=-1, min_leaf=20, lr=0.01 → F1=0.6248\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=-1, min_leaf=20, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=-1, min_leaf=20, lr=0.1 → F1=0.6196\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=-1, min_leaf=50, lr=0.01 → F1=0.6248\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=-1, min_leaf=50, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=-1, min_leaf=50, lr=0.1 → F1=0.6196\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=-1, min_leaf=100, lr=0.01 → F1=0.6247\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=-1, min_leaf=100, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=-1, min_leaf=100, lr=0.1 → F1=0.6196\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[40]\tvalid_0's binary_logloss: 0.694201\n",
            "leaves=127, depth=10, min_leaf=20, lr=0.01 → F1=0.6207\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=127, depth=10, min_leaf=20, lr=0.05 → F1=0.6209\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694197\n",
            "leaves=127, depth=10, min_leaf=20, lr=0.1 → F1=0.6188\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[40]\tvalid_0's binary_logloss: 0.694201\n",
            "leaves=127, depth=10, min_leaf=50, lr=0.01 → F1=0.6207\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=127, depth=10, min_leaf=50, lr=0.05 → F1=0.6209\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694197\n",
            "leaves=127, depth=10, min_leaf=50, lr=0.1 → F1=0.6188\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[40]\tvalid_0's binary_logloss: 0.694202\n",
            "leaves=127, depth=10, min_leaf=100, lr=0.01 → F1=0.6206\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's binary_logloss: 0.694208\n",
            "leaves=127, depth=10, min_leaf=100, lr=0.05 → F1=0.6209\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694197\n",
            "leaves=127, depth=10, min_leaf=100, lr=0.1 → F1=0.6188\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=20, min_leaf=20, lr=0.01 → F1=0.6248\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=20, min_leaf=20, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=20, min_leaf=20, lr=0.1 → F1=0.6196\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=20, min_leaf=50, lr=0.01 → F1=0.6248\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=20, min_leaf=50, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=20, min_leaf=50, lr=0.1 → F1=0.6196\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's binary_logloss: 0.694214\n",
            "leaves=127, depth=20, min_leaf=100, lr=0.01 → F1=0.6247\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's binary_logloss: 0.694213\n",
            "leaves=127, depth=20, min_leaf=100, lr=0.05 → F1=0.6243\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's binary_logloss: 0.694215\n",
            "leaves=127, depth=20, min_leaf=100, lr=0.1 → F1=0.6196\n",
            "\n",
            "Best hyperparameters on validation:\n",
            "{'n_estimators': 200, 'random_state': 42, 'n_jobs': -1, 'verbosity': -1, 'num_leaves': 127, 'max_depth': -1, 'min_data_in_leaf': 20, 'learning_rate': 0.01}\n",
            "Best F1 on validation: 0.6248\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[20]\tvalid_0's binary_logloss: 0.69438\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's binary_logloss: 0.694196\n",
            "\n",
            "Hybrid CNN–BiLSTM–GRU → LightGBM Performance:\n",
            "  Accuracy : 0.5170\n",
            "  Precision: 0.5122\n",
            "  Recall   : 0.8782\n",
            "  F1 Score : 0.6471\n",
            "  ROC AUC  : 0.5215\n",
            "Confusion Matrix:\n",
            "[[ 42464 240893]\n",
            " [ 35100 252986]]\n"
          ]
        }
      ]
    }
  ]
}